{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataloader.runPipeline() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m tmp \u001b[39m=\u001b[39m dataloader(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mclover\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m imu, rotor, mocap \u001b[39m=\u001b[39m tmp\u001b[39m.\u001b[39;49mrunPipeline(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m tmp\u001b[39m.\u001b[39mhomogenizeData()\n\u001b[0;32m     13\u001b[0m data \u001b[39m=\u001b[39m tmp\u001b[39m.\u001b[39mConcatData\n",
      "\u001b[1;31mTypeError\u001b[0m: dataloader.runPipeline() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sys.path.insert(0,\"..\")\n",
    "from dataloader import dataloader\n",
    "device = torch.device(\"cuda\")\n",
    "tmp = dataloader(r\"..\\data\\clover\")\n",
    "imu, rotor, mocap = tmp.runPipeline(1)\n",
    "tmp.homogenizeData()\n",
    "data = tmp.ConcatData\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['g_x'] = 0.0\n",
    "data['g_y'] = 0.0\n",
    "data['g_z'] = -9.81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = data[['linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z',\n",
    "                        'angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z', 'g_x', 'g_y', 'g_z']].to_numpy()\n",
    "sensor_readings = torch.tensor(sensor_readings, device=device)\n",
    "sensor_readings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulers = data[['phi', 'theta', 'psi']].to_numpy()\n",
    "eulers = torch.tensor(eulers, device=device)\n",
    "eulers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class euler_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(9, 30, dtype=torch.float64)\n",
    "        self.layer2 = nn.Linear(30, 30, dtype=torch.float64)\n",
    "        self.layer3 = nn.Linear(30, 3, dtype=torch.float64)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, sensor_reading):\n",
    "        x = self.tanh(self.layer1(sensor_reading))\n",
    "        x = self.tanh(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EulerModel = euler_model().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "dataset = torch.utils.data.TensorDataset(sensor_readings, eulers)\n",
    "train_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, [int(0.8*len(dataset)), len(dataset)-int(0.8*len(dataset))])\n",
    "optimizer = torch.optim.Adam(EulerModel.parameters(), lr=lr)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=10000, shuffle=True)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "epoch_num = 1000\n",
    "# axa,y,az,gx,-9.81\n",
    "for epoch in range(epoch_num):\n",
    "    for batch in dataloader:\n",
    "        sensor_reading, euler = batch\n",
    "        prediction = EulerModel(sensor_readings)\n",
    "        loss = loss_fn(prediction, eulers)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "EulerModel.eval()\n",
    "# sensor_readings, eulers = test_set[:]\n",
    "with torch.no_grad():\n",
    "    prediction = EulerModel(sensor_readings)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(20, 10))\n",
    "\n",
    "axs[0].plot(prediction[:, 0].cpu().numpy(), label='Predicted')\n",
    "axs[0].plot(eulers[:, 0].cpu().numpy(), label='Actual')\n",
    "axs[0].set_title('Roll')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(prediction[:, 1].cpu().numpy(), label='Predicted')\n",
    "axs[1].plot(eulers[:, 1].cpu().numpy(), label='Actual')\n",
    "axs[1].set_title('Pitch')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(prediction[:, 2].cpu().numpy(), label='Predicted')\n",
    "axs[2].plot(eulers[:, 2].cpu().numpy(), label='Actual')\n",
    "axs[2].set_title('Yaw')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# x1, y1, z1 = data['pose.position.x'].to_numpy(\n",
    "# ), data['pose.position.y'].to_numpy(), data['pose.position.z'].to_numpy()\n",
    "# xA1, yA1, zA1 = data['psi'].to_numpy(\n",
    "# ), data['theta'].to_numpy(), data['phi'].to_numpy()\n",
    "# dt = np.append(0, np.diff(data['Time'].to_numpy()))\n",
    "# r1, r2, r3, r4 = data['rpm_0'].to_numpy(), data['rpm_1'].to_numpy(\n",
    "# ), data['rpm_2'].to_numpy(), data['rpm_3'].to_numpy()\n",
    "\n",
    "\n",
    "# TrajectorySize = 25000  # 15*350\n",
    "# TrainTrajectorySize = int(0.8*TrajectorySize)\n",
    "# St = 0  # Start index\n",
    "\n",
    "\n",
    "# xTrain = np.stack((r1[St:St + TrajectorySize], r2[St:St + TrajectorySize],\n",
    "#                   r3[St:St + TrajectorySize], r4[St:St + TrajectorySize], dt[St:St + TrajectorySize]), axis=1)\n",
    "# yTrain = np.stack((x1[St:St + TrajectorySize], y1[St:St + TrajectorySize], z1[St:St + TrajectorySize],\n",
    "#                    xA1[St:St + TrajectorySize], yA1[St:St + TrajectorySize], zA1[St:St + TrajectorySize]), axis=1)\n",
    "\n",
    "\n",
    "# # torch.tensor(xTrain[:7000], dtype=torch.float32)\n",
    "# train_x = xTrain[:TrainTrajectorySize]\n",
    "# # torch.tensor(yTrain[:7000], dtype=torch.float32)\n",
    "# train_y = yTrain[:TrainTrajectorySize]\n",
    "# # torch.tensor(xTrain[7000:], dtype=torch.float32)\n",
    "# test_x = xTrain[TrainTrajectorySize:]\n",
    "# # torch.tensor(yTrain[7000:], dtype=torch.float32)\n",
    "# test_y = yTrain[TrainTrajectorySize:]\n",
    "\n",
    "# xTrain = torch.tensor(xTrain, device=device)\n",
    "# yTrain = torch.tensor(yTrain, device=device)\n",
    "# train_x = torch.tensor(train_x, device=device)\n",
    "# train_y = torch.tensor(train_y, device=device)\n",
    "# test_x = torch.tensor(test_x, device=device)\n",
    "# test_y = torch.tensor(test_y, device=device)\n",
    "\n",
    "# ax = plt.figure().add_subplot(projection='3d')\n",
    "# ax.plot(train_y[:, 0].cpu().numpy(), train_y[:, 1].cpu(\n",
    "# ).numpy(), train_y[:, 2].cpu().numpy(), '.b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### NODE #####\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchdiffeq import odeint_adjoint as odeint\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# method = 'dopri5'\n",
    "# batch_time = 45\n",
    "# batch_size = TrainTrajectorySize-100\n",
    "# niters = 200000\n",
    "# test_freq = 10000\n",
    "# viz = 'store_true'\n",
    "# adjoint = 'store_true'\n",
    "\n",
    "\n",
    "# # def mini_batch(yTrain, xTrain, size, batch_size, batch_time):\n",
    "\n",
    "# #     s = torch.from_numpy(np.random.choice(\n",
    "# #         np.arange(size-batch_time, dtype=np.int64), batch_size, replace=False))\n",
    "# #     batch_y0 = xTrain[s, :4]\n",
    "# #     batch_x = xTrain[:batch_time, 4]\n",
    "# #     batch_y = torch.stack([torch.Tensor(xTrain[s + i, :4])\n",
    "# #                           for i in range(batch_time)], dim=0)\n",
    "# #     batch_yy = yTrain[s, :]\n",
    "# #     batch_yy1 = yTrain[s+1, :]\n",
    "\n",
    "# #     return batch_y0, batch_x, batch_y, batch_yy, batch_yy1\n",
    "\n",
    "# def mini_batch(yTrain, xTrain, size, batch_size, batch_time):\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     s = torch.randint(0, size-batch_time, (batch_size,),\n",
    "#                       dtype=torch.int64, device=device)\n",
    "#     batch_y0 = xTrain[s, :4]\n",
    "#     batch_x = xTrain[:batch_time, 4]\n",
    "#     batch_y = torch.stack([xTrain[s + i, :4]\n",
    "#                           for i in range(batch_time)], dim=0)\n",
    "#     batch_yy = yTrain[s, :]\n",
    "#     batch_yy1 = yTrain[s+1, :]\n",
    "\n",
    "#     return batch_y0, batch_x, batch_y, batch_yy, batch_yy1\n",
    "\n",
    "# # def TrainNODENetwork(yTrain, xTrain, size, batch_size, batch_time, FuncControl, FuncDynamics, niters=13000,):\n",
    "\n",
    "# #     parameters = list(FuncControl.parameters()) + \\\n",
    "# #         list(FuncDynamics.parameters())\n",
    "# #     # optimizerD = optim.Adam(params=parameters, lr=1e-3)\n",
    "# #     optimizer = optim.Adadelta(\n",
    "# #         params=parameters, lr=1, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "# #     for itr in range(1, niters + 1):\n",
    "# #         optimizer.zero_grad()\n",
    "# #         batch_y0, batch_x, batch_y, batch_yy, batch_yy1 = mini_batch(\n",
    "# #             yTrain, xTrain, size, batch_size, batch_time)\n",
    "# #         # pred_y = odeint(FuncControl, torch.Tensor(\n",
    "# #             # batch_y0).to(device = 'cuda:0'), torch.Tensor(batch_x))\n",
    "\n",
    "# #         XDynamics = torch.cat((batch_y0, batch_yy), 1).to(\n",
    "# #             device='cuda:0')  # pred_y[1,:,:]\n",
    "# #         pred_yy = FuncDynamics(XDynamics).to(device='cuda:0', dtype=torch.float64)\n",
    "# #         lossD = torch.mean(\n",
    "# #             torch.abs(pred_yy - batch_yy1))\n",
    "# #         # lossC = torch.mean(torch.abs(pred_y - torch.Tensor(batch_y)))\n",
    "\n",
    "# #         loss = lossD  # + lossC\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "\n",
    "# #         if itr % test_freq == 0:\n",
    "# #             '''with torch.no_grad():\n",
    "# #                 pred_y = odeint(Func, torch.Tensor(y0[1,:]), t)\n",
    "# #                 loss = torch.norm(pred_y - torch.Tensor(y[:,1,:]))'''\n",
    "# #             print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n",
    "\n",
    "# #     return FuncControl, FuncDynamics\n",
    "\n",
    "\n",
    "# class ODEFunc(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(4, 30),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(30, 30),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(30, 4),\n",
    "#         )\n",
    "#         self.net = self.net.float()\n",
    "#         self.net.apply(self._apply_wt_init)\n",
    "\n",
    "#     def forward(self, t, y):\n",
    "#         return self.net(y)\n",
    "\n",
    "#     def _apply_wt_init(self, layer):\n",
    "#         if isinstance(layer, nn.Linear):\n",
    "#             nn.init.normal_(layer.weight, mean=0, std=0.1)\n",
    "#             nn.init.constant_(layer.bias, val=0)\n",
    "\n",
    "\n",
    "# class Func2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             # nn.BatchNorm1d(10),\n",
    "#             nn.Linear(10, 175),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.BatchNorm1d(175),\n",
    "#             nn.Linear(175, 35),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.BatchNorm1d(35),\n",
    "#             nn.Linear(35, 6),\n",
    "#         )\n",
    "#         self.net = self.net.to(dtype=torch.float64)\n",
    "#         self.net.apply(self._apply_wt_init)\n",
    "\n",
    "#     def forward(self, y):\n",
    "#         return self.net(y)\n",
    "\n",
    "#     def _apply_wt_init(self, layer):\n",
    "#         if isinstance(layer, nn.Linear):\n",
    "#             nn.init.normal_(layer.weight, mean=0, std=0.1)\n",
    "#             nn.init.constant_(layer.bias, val=0)\n",
    "\n",
    "\n",
    "# FuncControl = ODEFunc().to(device=device)\n",
    "# FuncDynamics = Func2().to(device=device)\n",
    "\n",
    "# train_y = torch.tensor(train_y, device=device)\n",
    "# train_x = torch.tensor(train_x, device=device)\n",
    "\n",
    "\n",
    "# # FuncControl, FuncDynamics = TrainNODENetwork(\n",
    "# #     train_y, train_x, TrainTrajectorySize, batch_size, batch_time, FuncControl, FuncDynamics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = list(FuncControl.parameters()) + list(FuncDynamics.parameters())\n",
    "# optimizer = optim.Adadelta(params=parameters, lr=0.1,\n",
    "#                            rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "# batchy0s = []\n",
    "# batchxs = []\n",
    "# batchys = []\n",
    "# batchyys = []\n",
    "# batchyy1s = []\n",
    "\n",
    "# # for itr in range(1, niters + 1):\n",
    "# #     batch_y0, batch_x, batch_y, batch_yy, batch_yy1 = mini_batch(\n",
    "# #         yTrain, xTrain, TrainTrajectorySize, batch_size, batch_time)\n",
    "# #     batchy0s.append(batch_y0)\n",
    "# #     batchxs.append(batch_x)\n",
    "# #     batchys.append(batch_y)\n",
    "# #     batchyys.append(batch_yy)\n",
    "# #     batchyy1s.append(batch_yy1)\n",
    "# niters = 5000\n",
    "# test_freq = 1000\n",
    "# for itr in range(1, niters + 1):\n",
    "#     optimizer.zero_grad()\n",
    "#     # batch_y0 = batchy0s[itr-1]\n",
    "#     # batch_x = batchxs[itr-1]\n",
    "#     # batch_y = batchys[itr-1]\n",
    "#     # batch_yy = batchyys[itr-1]\n",
    "#     # batch_yy1 = batchyy1s[itr-1]\n",
    "\n",
    "#     batch_y0, batch_x, batch_y, batch_yy, batch_yy1 = mini_batch(\n",
    "#         yTrain, xTrain, TrainTrajectorySize, batch_size, batch_time)\n",
    "\n",
    "#     XDynamics = torch.cat([batch_y0, batch_yy], dim=1)\n",
    "#     pred_yy = FuncDynamics(XDynamics)\n",
    "#     loss = torch.mean(torch.abs(pred_yy - batch_yy1))\n",
    "\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if itr % test_freq == 0:\n",
    "#         print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# ax = plt.figure().add_subplot(projection='3d')\n",
    "# ax.plot(train_y[::2, 0].cpu().detach().numpy(), train_y[::2, 1].cpu(\n",
    "# ).detach().numpy(), train_y[::2, 2].cpu().detach().numpy(), '.r')\n",
    "\n",
    "# y0 = train_y[0, :]\n",
    "# u0 = train_x[0, :4]\n",
    "# FuncDynamics.eval()\n",
    "# x = []\n",
    "# y = []\n",
    "# z = []\n",
    "# for i in range(TrainTrajectorySize):\n",
    "\n",
    "#     # pred_u = odeint(FuncControl, torch.Tensor(u0), torch.Tensor(train_x[i:i+5,4]))\n",
    "\n",
    "#     u0 = train_x[i, :4]  # pred_u[1,:].detach().numpy()\n",
    "#     if i % 500 == 0:\n",
    "#         m = deepcopy(train_y[i, :])\n",
    "\n",
    "#         # m[0] += (np.random.uniform()-0.5)\n",
    "#         # m[1] += (np.random.uniform()-0.5)\n",
    "#         # m[2] += (np.random.uniform()-0.5)\n",
    "#     else:\n",
    "#         m = pred_y\n",
    "#     # print(\"In\",m)\n",
    "#     XDynamics = torch.cat(\n",
    "#         (torch.Tensor(u0), torch.Tensor(m).to(device='cuda:0'))).to(device='cuda:0').unsqueeze(0)\n",
    "#     pred_y = FuncDynamics(XDynamics).flatten()\n",
    "#     y0 = pred_y.to('cpu').detach().numpy()\n",
    "#     # print(\"Out:\", y0)\n",
    "#     # if i == 5:\n",
    "#     #     break\n",
    "#     x.append(y0[0])\n",
    "#     y.append(y0[1])\n",
    "#     z.append(y0[2])\n",
    "\n",
    "# ax.scatter(x[0::2], y[::2], z[::2], s=8, c='b')\n",
    "# plt.xlim([-5, 5])\n",
    "# plt.ylim([-5, 5])\n",
    "# plt.gca().set_zlim([-5, 0])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# plt.figure()\n",
    "# xt = []\n",
    "# yt = []\n",
    "# zt = []\n",
    "\n",
    "# y0 = train_y[0, :]\n",
    "# u0 = train_x[0, :4]\n",
    "# FuncDynamics.eval()\n",
    "# x = []\n",
    "# y = []\n",
    "# z = []\n",
    "# for i in range(TrainTrajectorySize):\n",
    "\n",
    "#     # pred_u = odeint(FuncControl, torch.Tensor(u0), torch.Tensor(train_x[i:i+5,4]))\n",
    "\n",
    "#     u0 = train_x[i, :4]  # pred_u[1,:].detach().numpy()\n",
    "#     if i % 500 == 0:\n",
    "#         m = deepcopy(train_y[i, :])\n",
    "\n",
    "#         # m[0] += (np.random.uniform()-0.5)\n",
    "#         # m[1] += (np.random.uniform()-0.5)\n",
    "#         # m[2] += (np.random.uniform()-0.5)\n",
    "#     else:\n",
    "#         m = pred_y\n",
    "#     # print(\"In\",m)\n",
    "#     XDynamics = torch.cat(\n",
    "#         (torch.Tensor(u0), torch.Tensor(m).to(device='cuda:0'))).to(device='cuda:0').unsqueeze(0)\n",
    "#     pred_y = FuncDynamics(XDynamics).flatten()\n",
    "#     y0 = pred_y.to('cpu').detach().numpy()\n",
    "#     y0[3:] = np.arctan2(np.sin(y0[3:]), np.cos(y0[3:]))\n",
    "#     # print(\"Out:\", y0)\n",
    "#     # if i == 5:\n",
    "#     #     break\n",
    "#     x.append(y0[3])\n",
    "#     y.append(y0[4])\n",
    "#     z.append(y0[5])\n",
    "#     xt.append(train_y[i, 3].cpu().detach().numpy())\n",
    "#     yt.append(train_y[i, 4].cpu().detach().numpy())\n",
    "#     zt.append(train_y[i, 5].cpu().detach().numpy())\n",
    "\n",
    "# plt.plot(np.array(xt)*10, 'r')\n",
    "# plt.plot(x, 'b')\n",
    "\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(yt, 'r')\n",
    "# plt.plot(y, 'b')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(yt, 'r')\n",
    "# plt.plot(y, 'b')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(FuncDynamics.state_dict(), 'FuncDynamics2.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadModel = Func2().to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadModel.load_state_dict(torch.load('FuncDynamics.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadModel.eval()\n",
    "# ax = plt.figure().add_subplot(projection='3d')\n",
    "# ax.plot(train_y[::2, 0].cpu().detach().numpy(), train_y[::2, 1].cpu(\n",
    "# ).detach().numpy(), train_y[::2, 2].cpu().detach().numpy(), '.r')\n",
    "\n",
    "# y0 = train_y[0, :]\n",
    "# u0 = train_x[0, :4]\n",
    "# FuncDynamics.eval()\n",
    "# x = []\n",
    "# y = []\n",
    "# z = []\n",
    "# for i in range(TrainTrajectorySize):\n",
    "\n",
    "#     # pred_u = odeint(FuncControl, torch.Tensor(u0), torch.Tensor(train_x[i:i+5,4]))\n",
    "#     u0 = train_x[i, :4]  # pred_u[1,:].detach().numpy()\n",
    "#     m = deepcopy(train_y[i, :])\n",
    "#     m[0] += (np.random.uniform()-0.5)*3\n",
    "#     m[1] += (np.random.uniform()-0.5)*3\n",
    "#     m[2] += (np.random.uniform()-0.5)*3\n",
    "#     XDynamics = torch.cat(\n",
    "#         (torch.Tensor(u0), torch.Tensor(m).to(device='cuda:0'))).to(device='cuda:0').unsqueeze(0)\n",
    "#     pred_y = loadModel(XDynamics).flatten()\n",
    "#     y0 = pred_y.to('cpu').detach().numpy()\n",
    "#     x.append(y0[0])\n",
    "#     y.append(y0[1])\n",
    "#     z.append(y0[2])\n",
    "\n",
    "# ax.scatter(x[0::2], y[::2], z[::2], s=8, c='b')\n",
    "# plt.xlim([-5, 5])\n",
    "# plt.ylim([-5, 5])\n",
    "# plt.gca().set_zlim([-5, 0])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
